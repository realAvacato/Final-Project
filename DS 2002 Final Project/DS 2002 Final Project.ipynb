{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb2d753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pymongo\n",
    "import pyspark.pandas as pd  # This uses Koalas that is included in PySpark version 3.2 or newer.\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, BinaryType\n",
    "from pyspark.sql.types import ByteType, ShortType, IntegerType, LongType, FloatType, DecimalType\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pymongo\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab285b",
   "metadata": {},
   "source": [
    "Set Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure SQL Server Connection Information #####################\n",
    "jdbc_hostname = \"mysql-czhong.mysql.database.azure.com\"\n",
    "jdbc_port = 3306\n",
    "src_database = \"HR\"\n",
    "\n",
    "connection_properties = {\n",
    "  \"user\" : \"dsadmin\",\n",
    "  \"password\" : \"CatoZ0426\",\n",
    "  \"driver\" : \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}\n",
    "\n",
    "# MongoDB Atlas Connection Information ########################\n",
    "atlas_cluster_name = \"DS2002\"\n",
    "atlas_database_name = \"hr_db\"\n",
    "atlas_user_name = \"root\"\n",
    "atlas_password = \"gthgthgth\"\n",
    "\n",
    "# Data Files (JSON) Information ###############################\n",
    "dst_database = \"adventure_works\"\n",
    "\n",
    "base_dir = \"dbfs:/FileStore/ds3002-capstone\"\n",
    "database_dir = f\"{base_dir}/{dst_database}\"\n",
    "\n",
    "data_dir = f\"{base_dir}/source_data\"\n",
    "batch_dir = f\"{data_dir}/batch\"\n",
    "stream_dir = f\"{data_dir}/stream\"\n",
    "\n",
    "output_bronze = f\"{database_dir}/fact_sales_orders/bronze\"\n",
    "output_silver = f\"{database_dir}/fact_sales_orders/silver\"\n",
    "output_gold   = f\"{database_dir}/fact_sales_orders/gold\"\n",
    "\n",
    "# Delete the Streaming Files ################################## \n",
    "dbutils.fs.rm(f\"{database_dir}/fact_sales_orders\", True)\n",
    "\n",
    "# Delete the Database Files ###################################\n",
    "dbutils.fs.rm(database_dir, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
